# Tokenizer
Responsible to convert characters to specific tokens.

# Tokens
[List of tokens](./token_type.rs)  
[List of keywords](./keywords.rs)  
